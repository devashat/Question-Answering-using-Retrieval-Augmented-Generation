{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f1d34db-c141-44ea-9e82-b6e6678ab6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "891e4e3d-8b95-433c-bea0-df62c203313c",
   "metadata": {},
   "outputs": [],
   "source": [
    "passages_df = pd.read_csv(\"./passages.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e94aa05-0701-4e48-af06-b74163bb776a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>572ec434c246551400ce463c</td>\n",
       "      <td>Endangered_Species_Act</td>\n",
       "      <td>The \"Safe Harbor\" agreement is a voluntary agr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>573383e94776f41900660c5b</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Besides its prominence in sports, Notre Dame i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>56e7894300c9c71400d77268</td>\n",
       "      <td>Nanjing</td>\n",
       "      <td>It is believed that Nanjing was the largest ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>57327c59b9d445190005eb4c</td>\n",
       "      <td>Humanism</td>\n",
       "      <td>In the 6th century BCE, Taoist teacher Lao Tzu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5727a440ff5b5019007d91bb</td>\n",
       "      <td>Child_labour</td>\n",
       "      <td>According to Milton Friedman, before the Indus...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #                        id                     title  \\\n",
       "0  0  572ec434c246551400ce463c    Endangered_Species_Act   \n",
       "1  1  573383e94776f41900660c5b  University_of_Notre_Dame   \n",
       "2  2  56e7894300c9c71400d77268                   Nanjing   \n",
       "3  3  57327c59b9d445190005eb4c                  Humanism   \n",
       "4  4  5727a440ff5b5019007d91bb              Child_labour   \n",
       "\n",
       "                                             context  \n",
       "0  The \"Safe Harbor\" agreement is a voluntary agr...  \n",
       "1  Besides its prominence in sports, Notre Dame i...  \n",
       "2  It is believed that Nanjing was the largest ci...  \n",
       "3  In the 6th century BCE, Taoist teacher Lao Tzu...  \n",
       "4  According to Milton Friedman, before the Indus...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passages_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f024e07d-a343-484c-a529-61c162a62f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = passages_df['context'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffd01e4c-b97a-47ba-b611-876e7f58bc82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The \"Safe Harbor\" agreement is a voluntary agreement between the private landowner and FWS. The landowner agrees to alter the property to benefit or even attract a listed or proposed species in exchange for assurances that the FWS will permit future \"takes\" above a pre-determined level. The policy relies on the \"enhancement of survival\" provision of Section ยง1539(a)(1)(A). A landowner can have either a \"Safe Harbor\" agreement or an Incidental Take Permit, or both. The policy was developed by the Clinton Administration in 1999.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06519bea-23eb-4c00-acc8-a51c5dfa7978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0346643"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SentenceTransformer('sentence-transformers/roberta-base-nli-stsb-mean-tokens')\n",
    "document_embeddings = model.encode(documents)\n",
    "\n",
    "document_embeddings[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82e4cc73-faa0-4051-b2bb-9b47fef0fc65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function ndarray.astype>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_embeddings.astype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4845595b-2aa9-4645-9fd0-2343011fedf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Which presidential administration developed Sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>How many individual colleges are part of Notre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Where was the capital moved to?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Where could you read this information?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>What did parents do when the wages were finall...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #                                           question\n",
       "0  0  Which presidential administration developed Sa...\n",
       "1  1  How many individual colleges are part of Notre...\n",
       "2  2                    Where was the capital moved to?\n",
       "3  3             Where could you read this information?\n",
       "4  4  What did parents do when the wages were finall..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_df = pd.read_csv('./questions.csv')\n",
    "\n",
    "questions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cc63452-f3e9-4874-b975-95a3c0804867",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = questions_df['question'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c66aa61-33ec-4a38-b719-a570c7153630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Which presidential administration developed Safe Harbor policy?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "684beaee-5802-4d1b-b24a-181d1933462f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19474915"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_embeddings = model.encode(questions)\n",
    "\n",
    "question_embeddings[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2536876d-fa13-4635-951c-b9387f08a228",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0676f851-663c-47e3-82f3-fccb9dae98d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimension = document_embeddings.shape[1]\n",
    "\n",
    "dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb02f913-de28-4237-a146-30590763b05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(document_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84c24a1b-f56f-4775-a62f-19fb0c14f2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3  # Number of nearest neighbors to retrieve\n",
    "D, I = index.search(question_embeddings, k)  # D: distances, I: indices of the documents\n",
    "\n",
    "retrieved_docs = [documents[i] for i in I[0]]  # Retrieve documents based on indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7dd3c96-3466-4b97-86d6-c401706afec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The \"Safe Harbor\" agreement is a voluntary agreement between the private landowner and FWS. The landowner agrees to alter the property to benefit or even attract a listed or proposed species in exchange for assurances that the FWS will permit future \"takes\" above a pre-determined level. The policy relies on the \"enhancement of survival\" provision of Section ยง1539(a)(1)(A). A landowner can have either a \"Safe Harbor\" agreement or an Incidental Take Permit, or both. The policy was developed by the Clinton Administration in 1999.',\n",
       " 'The US Congress was urged to create the exemption by proponents of a conservation plan on San Bruno Mountain, California that was drafted in the early 1980s and is the first HCP in the nation. In the conference report on the 1982 amendments, Congress specified that it intended the San Bruno plan to act \"as a model\" for future conservation plans developed under the incidental take exemption provision and that \"the adequacy of similar conservation plans should be measured against the San Bruno plan\". Congress further noted that the San Bruno plan was based on \"an independent exhaustive biological study\" and protected at least 87% of the habitat of the listed butterflies that led to the development of the HCP.',\n",
       " 'The location on the banks of the river Rhine allowed Utrecht to become an important trade centre in the Northern Netherlands. The growing town Utrecht was granted city rights by Henry V in 1122. When the main flow of the Rhine moved south, the old bed, which still flowed through the heart of the town became evermore canalized; and the wharf system was built as an inner city harbour system. On the wharfs storage facilities (werfkelders) were built, on top of which the main street, including houses was constructed. The wharfs and the cellars are accessible from a platform at water level with stairs descending from the street level to form a unique structure.[nb 2] The relations between the bishop, who controlled many lands outside of the city, and the citizens of Utrecht was not always easy. The bishop, for example dammed the Kromme Rijn at Wijk bij Duurstede to protect his estates from flooding. This threatened shipping for the city and led the city of Utrecht to commission a canal to ensure access to the town for shipping trade: the Vaartse Rijn, connecting Utrecht to the Hollandse IJssel at IJsselstein.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a499ce7e-1460-41b2-ba9a-1caf29668d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \" \".join(retrieved_docs)\n",
    "question = \"Which presidential administration developed Safe Harbor policy?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b082d95-6ce2-4265-a6c0-32fec811df6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f7a85ad-02e7-468b-b50f-b972577ea3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (565 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clinton\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_name = \"google/flan-t5-base\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Prepare input for the model\n",
    "input_text = f\"Given the context: {context}, answer the question: {question}\"\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "\n",
    "# Generate an answer\n",
    "outputs = model.generate(input_ids, max_length=200, num_beams=5, early_stopping=True)\n",
    "answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb137195-668f-4a03-b371-6c66b28ba8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done generating answers and retrieving documents.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Number of nearest neighbors to retrieve\n",
    "k = 3\n",
    "\n",
    "# Prepare a list to hold answers and retrieved documents for each question\n",
    "answers_and_docs = []\n",
    "\n",
    "for idx, question_embedding in enumerate(question_embeddings):\n",
    "    # Search for the k nearest neighbors (retrieved documents)\n",
    "    D, I = index.search(np.array([question_embedding]), k)\n",
    "    \n",
    "    # Retrieve documents based on indices\n",
    "    retrieved_docs = [documents[i] for i in I[0]]\n",
    "    \n",
    "    # Concatenate retrieved documents for context\n",
    "    context = \" \".join(retrieved_docs)\n",
    "    \n",
    "    # Prepare input for the T5 model\n",
    "    input_text = f\"Given the context: {context}, answer the question: {questions[idx]}\"\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "    \n",
    "    # Generate an answer\n",
    "    outputs = model.generate(input_ids, max_length=200, num_beams=5, early_stopping=True)\n",
    "    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Append the answer and retrieved documents to the list\n",
    "    answers_and_docs.append({\n",
    "        \"question\": questions[idx],\n",
    "        \"answer\": answer,\n",
    "        \"retrieved_docs\": retrieved_docs\n",
    "    })\n",
    "\n",
    "# Convert the list of answers and documents to a DataFrame for easy viewing/exporting\n",
    "answers_df = pd.DataFrame(answers_and_docs)\n",
    "\n",
    "# Optionally, save the DataFrame to a new CSV file\n",
    "answers_df.to_csv('answers_and_retrieved_docs.csv', index=False)\n",
    "\n",
    "print(\"Done generating answers and retrieving documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27265526-7e46-4988-8744-c6b8584729a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
